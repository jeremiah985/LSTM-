#机器学习

##正则化

说人话->正则化就是规范化
具体而言：我们在一般判断误差的时候都是采用（预测值减去实际值）的平方，但是这样做的后果就是模型对于已有的数据拟合程度特别高，所以说模型的泛化能力就相对而言的减弱了，为了避免这种影响，我们引入了惩罚函数（在上述的基础上加上每个参数的平方或者说是是绝对值）


在机器学习中，正则化是一种用于控制模型复杂度并防止过拟合的技术。正则化通过在模型的目标函数中引入额外的惩罚项，以限制模型参数的大小或复杂度。

常见的正则化方法有两种：L1正则化（L1 Regularization）和L2正则化（L2 Regularization）。

1. L1正则化（L1 Regularization）：也被称为Lasso正则化，它通过在目标函数中添加参数的绝对值之和来惩罚模型的复杂度。L1正则化倾向于产生稀疏权重矩阵，即将一些特征的权重变为零，从而减少模型的复杂度。这对于特征选择和稀疏性很有用。
   

3. L2正则化（L2 Regularization）：也被称为Ridge正则化，它通过在目标函数中添加参数的平方和来惩罚模型的复杂度。L2正则化倾向于使权重较小，但不会强制为零，因此它更适合于防止过拟合并改善模型的泛化能力。




这些正则化方法的惩罚项可以与模型的损失函数相结合，形成一个新的目标函数。在训练过程中，优化算法将尝试最小化这个新的目标函数，从而找到适合的模型参数。

正则化在机器学习中起到了平衡模型复杂度和拟合数据的作用。它可以帮助避免过拟合，提高模型的泛化能力，并在特征选择中起到重要的作用。


##决策树

